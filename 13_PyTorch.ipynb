{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca2133d-8ba8-4336-b40c-57b7226f97d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# .to(device)\n",
    "# !nvidia-smi\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd36ead6-2cf8-4aef-81d5-0dc55546b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c0c6a8-f2dd-4fcc-9712-21258c73a3b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_ch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m----> 2\u001b[0m             nn\u001b[38;5;241m.\u001b[39mLinear(in_ch, \u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m      3\u001b[0m             nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      4\u001b[0m             nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m32\u001b[39m, out_ch, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m      5\u001b[0m             nn\u001b[38;5;241m.\u001b[39mReLU()\n\u001b[0;32m      6\u001b[0m             \n\u001b[0;32m      7\u001b[0m         )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimpleModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_ch, out_ch):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'in_ch' is not defined"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(in_ch, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_ch, bias=False),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_ch, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_ch, bias=False),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_ch, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_ch, bias=False),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.decoder(x)\n",
    "\n",
    "model = SimpleModel(64, 10).to(device)\n",
    "\n",
    "x = torch.rand(4, 64).to(device)\n",
    "y = torch.rand(4, 10).to(device)\n",
    "\n",
    "y_pred = model(x)\n",
    "y_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2d628bc-a1a4-4095-ab50-e407d0b7de5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность выходного массива: torch.Size([8, 4])\n",
      "Сам массив: tensor([[0.2189, 0.2574, 0.2755, 0.2481],\n",
      "        [0.2125, 0.2939, 0.2289, 0.2647],\n",
      "        [0.2407, 0.2486, 0.2497, 0.2609],\n",
      "        [0.2639, 0.2832, 0.2375, 0.2154],\n",
      "        [0.2011, 0.2551, 0.2959, 0.2478],\n",
      "        [0.2624, 0.2473, 0.2456, 0.2447],\n",
      "        [0.2320, 0.2279, 0.2750, 0.2651],\n",
      "        [0.2198, 0.2167, 0.2457, 0.3178]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SecondModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),          \n",
    "            nn.Linear(64, 16),\n",
    "            nn.Tanh(),        \n",
    "            nn.Linear(16, 4),   \n",
    "            nn.Softmax(dim=1)    \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "model = SecondModel().to(device)\n",
    "x = torch.randn(8,256).to(device)\n",
    "y = model(x)\n",
    "\n",
    "print(f'Размерность выходного массива: {y.shape}')\n",
    "print(f'Сам массив: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c0be708-64ba-4387-8afd-a747a8ae2084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность выходного массива: torch.Size([5, 16, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"19х19x3 -> 18x18x8 -> 9x9x8 -> 8x8x16 -> 4x4x16\"\"\"\n",
    "\n",
    "class ThirdModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "model = ThirdModel().to(device)\n",
    "\n",
    "x = torch.randn(5, 3, 19, 19).to(device)\n",
    "y = model(x)\n",
    "\n",
    "print(f'Размерность выходного массива: {y.shape}')\n",
    "# print(f'Сам массив: {y}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ebbfc26-779e-4479-8923-76d36ffa7509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность выходного массива: torch.Size([5, 4])\n",
      "Сам массив: tensor([[0.2836, 0.2546, 0.2176, 0.2442],\n",
      "        [0.2863, 0.2532, 0.2197, 0.2407],\n",
      "        [0.2862, 0.2535, 0.2222, 0.2381],\n",
      "        [0.2784, 0.2632, 0.2166, 0.2418],\n",
      "        [0.2831, 0.2553, 0.2295, 0.2321]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fst = SimpleModel(in_ch=19*19, out_ch=256)\n",
    "        self.snd = SecondModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fst(x)\n",
    "        x = self.snd(x)\n",
    "        return x\n",
    "\n",
    "model = CombinedModel().to(device)\n",
    "\n",
    "x = torch.randn(5,1,19,19).to(device)\n",
    "\n",
    "y = model(x)\n",
    "\n",
    "print(f'Размерность выходного массива: {y.shape}')\n",
    "print(f'Сам массив: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef04e284-84d8-4c29-925d-5cf8fb38e4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets is UpToDate\n"
     ]
    }
   ],
   "source": [
    "#13 - LAB\n",
    "transform = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.5), (0.5))\n",
    "                                            ])\n",
    "\n",
    "# Downloading the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/train\", train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/test\", train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "transform = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.5), (0.5))\n",
    "                                            ])\n",
    "\n",
    "# Downloading the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/train\", train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./MNIST/test\", train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False)\n",
    "\n",
    "def encode_label(j):\n",
    "    # 5 -> [[0], [0], [0], [0], [0], [1], [0], [0], [0], [0]]\n",
    "    e = np.zeros((10,1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "def shape_data(data):\n",
    "    features = [np.reshape(x[0][0].numpy(), (784,1)) for x in data]\n",
    "    labels = [encode_label(y[1]) for y in data]\n",
    "    return zip(features, labels)\n",
    "\n",
    "test1 = train_dataset[0]\n",
    "test2 = [test1]\n",
    "reshape = shape_data(test2)\n",
    "list(reshape)\n",
    "train = shape_data(train_dataset)\n",
    "test = shape_data(test_dataset)\n",
    "train = list(train)\n",
    "test = list(test)\n",
    "print(\"datasets is UpToDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70b995a-76c7-4888-84a2-7227daadae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared\n"
     ]
    }
   ],
   "source": [
    "class MNISTO(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fst_layer = nn.Linear(28 * 28, 128)\n",
    "        self.snd_layer = nn.Linear(128,64)\n",
    "        self.trd_layer = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Преобразование входных данных в вектор (batch_size, 28*28)\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # Первый слой + ReLU\n",
    "        x = torch.relu(self.fst_layer(x))\n",
    "        # Второй слой + ReLU\n",
    "        x = torch.relu(self.snd_layer(x))\n",
    "        # Выходной слой + Softmax\n",
    "        x = torch.softmax(self.trd_layer(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = MNISTO().to(device)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    features = [torch.tensor(feature, dtype=torch.float32).T.to(device) for feature, _ in data]\n",
    "    labels = [torch.tensor(label, dtype=torch.float32).squeeze().argmax().to(device) for _, label in data]\n",
    "    return list(zip(features, labels))\n",
    "\n",
    "train_data = prepare_data(train)\n",
    "test_data = prepare_data(test)\n",
    "\n",
    "print(\"Data prepared\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc22ac4-3a68-4407-8405-a752eca7627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 7511.6784\n",
      "Epoch 2/100, Loss: 7512.4718\n",
      "Epoch 3/100, Loss: 7575.7187\n",
      "Epoch 4/100, Loss: 7636.5665\n",
      "Epoch 5/100, Loss: 7542.9576\n",
      "Epoch 6/100, Loss: 7533.8996\n",
      "Epoch 7/100, Loss: 7529.8857\n",
      "Epoch 8/100, Loss: 7528.4128\n",
      "Epoch 9/100, Loss: 7509.0405\n",
      "Epoch 10/100, Loss: 7537.9921\n",
      "Epoch 11/100, Loss: 7506.5427\n",
      "Epoch 12/100, Loss: 7537.8840\n",
      "Epoch 13/100, Loss: 7608.2051\n",
      "Epoch 14/100, Loss: 7506.7907\n",
      "Epoch 15/100, Loss: 7526.9708\n",
      "Epoch 16/100, Loss: 7549.7040\n",
      "Epoch 17/100, Loss: 7521.5237\n",
      "Epoch 18/100, Loss: 7518.5095\n",
      "Epoch 19/100, Loss: 7526.9869\n",
      "Epoch 20/100, Loss: 7544.4642\n",
      "Epoch 21/100, Loss: 7612.8335\n",
      "Epoch 22/100, Loss: 7503.3767\n",
      "Epoch 23/100, Loss: 7483.1296\n",
      "Epoch 24/100, Loss: 7512.3214\n",
      "Epoch 25/100, Loss: 7539.5740\n",
      "Epoch 26/100, Loss: 7491.2384\n",
      "Epoch 27/100, Loss: 7499.7509\n",
      "Epoch 28/100, Loss: 7490.7639\n",
      "Epoch 29/100, Loss: 7507.4950\n",
      "Epoch 30/100, Loss: 7504.3880\n",
      "Epoch 31/100, Loss: 7474.5914\n",
      "Epoch 32/100, Loss: 7508.2454\n",
      "Epoch 33/100, Loss: 7513.4105\n",
      "Epoch 34/100, Loss: 7525.7966\n",
      "Epoch 35/100, Loss: 7519.7293\n",
      "Epoch 36/100, Loss: 7513.2248\n",
      "Epoch 37/100, Loss: 7465.7491\n",
      "Epoch 38/100, Loss: 7527.7586\n",
      "Epoch 39/100, Loss: 7495.9403\n",
      "Epoch 40/100, Loss: 7481.9370\n",
      "Epoch 41/100, Loss: 7501.8123\n",
      "Epoch 42/100, Loss: 7545.7165\n",
      "Epoch 43/100, Loss: 7511.3062\n",
      "Epoch 44/100, Loss: 7498.9515\n",
      "Epoch 45/100, Loss: 7490.8996\n",
      "Epoch 46/100, Loss: 7546.4439\n",
      "Epoch 47/100, Loss: 7517.2509\n",
      "Epoch 48/100, Loss: 7465.4791\n",
      "Epoch 49/100, Loss: 7470.4877\n",
      "Epoch 50/100, Loss: 7494.0762\n",
      "Epoch 51/100, Loss: 7481.8613\n",
      "Epoch 52/100, Loss: 7509.3033\n",
      "Epoch 53/100, Loss: 7536.5974\n",
      "Epoch 54/100, Loss: 7467.6983\n",
      "Epoch 55/100, Loss: 7478.4631\n",
      "Epoch 56/100, Loss: 7526.3917\n",
      "Epoch 57/100, Loss: 7540.7085\n",
      "Epoch 58/100, Loss: 7525.6400\n",
      "Epoch 59/100, Loss: 7504.8237\n",
      "Epoch 60/100, Loss: 7543.7954\n",
      "Epoch 61/100, Loss: 7511.6813\n",
      "Epoch 62/100, Loss: 7495.0000\n",
      "Epoch 63/100, Loss: 7459.9480\n",
      "Epoch 64/100, Loss: 7452.6888\n",
      "Epoch 65/100, Loss: 7467.8585\n",
      "Epoch 66/100, Loss: 7453.7401\n",
      "Epoch 67/100, Loss: 7453.0271\n",
      "Epoch 68/100, Loss: 7530.2156\n",
      "Epoch 69/100, Loss: 7469.7293\n",
      "Epoch 70/100, Loss: 7486.9535\n",
      "Epoch 71/100, Loss: 7501.7988\n",
      "Epoch 72/100, Loss: 7454.4203\n",
      "Epoch 73/100, Loss: 7439.7512\n",
      "Epoch 74/100, Loss: 7475.0756\n",
      "Epoch 75/100, Loss: 7479.3970\n",
      "Epoch 76/100, Loss: 7464.6010\n",
      "Epoch 77/100, Loss: 7521.6085\n",
      "Epoch 78/100, Loss: 7543.2351\n",
      "Epoch 79/100, Loss: 7521.3626\n",
      "Epoch 80/100, Loss: 7534.0343\n",
      "Epoch 81/100, Loss: 7503.8007\n",
      "Epoch 82/100, Loss: 7518.0724\n",
      "Epoch 83/100, Loss: 7505.6065\n",
      "Epoch 84/100, Loss: 7514.5037\n",
      "Epoch 85/100, Loss: 7478.4917\n",
      "Epoch 86/100, Loss: 7465.2258\n",
      "Epoch 87/100, Loss: 7486.5840\n",
      "Epoch 88/100, Loss: 7462.7075\n",
      "Epoch 89/100, Loss: 7489.9625\n",
      "Epoch 90/100, Loss: 7489.0499\n",
      "Epoch 91/100, Loss: 7493.0244\n",
      "Epoch 92/100, Loss: 7473.7017\n",
      "Epoch 93/100, Loss: 7519.3021\n",
      "Epoch 94/100, Loss: 7508.5174\n",
      "Epoch 95/100, Loss: 7475.8399\n",
      "Epoch 96/100, Loss: 7455.8970\n",
      "Epoch 97/100, Loss: 7450.4993\n",
      "Epoch 98/100, Loss: 7467.5754\n",
      "Epoch 99/100, Loss: 7461.2122\n",
      "Epoch 100/100, Loss: 7466.1225\n",
      "Accuracy on test set: 95.03%\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Устанавливаем модель в режим обучения\n",
    "    total_loss = 0\n",
    "    for feature, label in train_data[:5000]:\n",
    "        # Прямой проход\n",
    "        output = model(feature.unsqueeze(0))  # Добавляем размер батча\n",
    "        loss = loss_fn(output, label.unsqueeze(0))  # Loss ожидает батч, поэтому добавляем размерность\n",
    "\n",
    "        # Обратный проход и обновление весов\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Оценка модели\n",
    "model.eval()  # Устанавливаем модель в режим оценки\n",
    "correct = 0\n",
    "total = len(test_data)\n",
    "with torch.no_grad():\n",
    "    for feature, label in test_data:\n",
    "        output = model(feature.unsqueeze(0))\n",
    "        predicted = torch.argmax(output, dim=1)\n",
    "        correct += (predicted == label).item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on test set: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc51fa-7721-496c-b320-32f738a85657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
