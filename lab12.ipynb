{
 "cells": [
  {
   "cell_type": "raw",
   "id": "18788053-5977-4d49-869d-c5f39aba06c0",
   "metadata": {},
   "source": [
    "1) Класс Neuron, имеющий вектор весов self._weigths\n",
    "\n",
    "2) Два метода класса Neuron: forward(x), backward(x, loss) - реализующих прямой и обратный проход по нейронной сети.\n",
    "\n",
    "Метод forward должен реализовывать логику работу нейрона: умножение входа на вес self._weigths, сложение и функцию активации сигмоиду. \n",
    "\n",
    "Метод backward должен реализовывать взятие производной от сигмоиды и используя состояние нейрона обновить его веса.\n",
    "\n",
    "3) Реализовать с помощью класса Neuron нейронную сеть с архитектурой из трёх нейронов, предложенную в статье. Для красоты обернуть в класс Model с методами forward и backward, реализующими правильное взаимодействие нейронов на прямом и обратном проходах. \n",
    "\n",
    "4) Реализовать тренировочный цикл следующего вида:\n",
    "  цикл (обучающие данные): \n",
    "    y = model.forward(x)\n",
    "    err = loss(y, label) \n",
    "    model.backward(x, err)\n",
    "\n",
    "В итоге обучения должны предсказываться значения аналогичные описанным в статье. {(0,0):0, (0,1):1, (1, 0):1, (1,1):0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae81e8aa-0914-49bf-aba3-62df23deb9e4",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, current loss: 0.5333648014406611\n",
      "Epoch: 2000, current loss: 0.18001020098339146\n",
      "Epoch: 3000, current loss: 0.013690209292316569\n",
      "Epoch: 4000, current loss: 0.005904546951804167\n",
      "Epoch: 5000, current loss: 0.003637231382728368\n",
      "Epoch: 6000, current loss: 0.0025952147192454776\n",
      "Epoch: 7000, current loss: 0.002005107246095236\n",
      "Epoch: 8000, current loss: 0.0016281141389553673\n",
      "Epoch: 9000, current loss: 0.0013675829146153993\n",
      "Epoch: 10000, current loss: 0.0011773014813068559\n",
      "\n",
      "Testing the XOR Model\n",
      "Input: [0 0], Predicted: 0, Actual: 0\n",
      "Input: [0 1], Predicted: 1, Actual: 1\n",
      "Input: [1 0], Predicted: 1, Actual: 1\n",
      "Input: [1 1], Predicted: 0, Actual: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, input_size, learning_rate=0.1):\n",
    "        self._weights = np.random.uniform(-0.5, 0.5, input_size)\n",
    "        self._bias = np.random.uniform(-0.5, 0.5)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self._input = x\n",
    "        self._z = np.dot(x, self._weights) + self._bias\n",
    "        self._output = self.sigmoid(self._z)\n",
    "        return self._output\n",
    "\n",
    "    def backward(self, x, loss):\n",
    "        activation_derivative = self.sigmoid_derivative(self._output)\n",
    "        delta = loss * activation_derivative\n",
    "        self._weights -= self.learning_rate * delta * self._input\n",
    "        self._bias -= self.learning_rate * delta\n",
    "# почему биас без инпута\n",
    "\n",
    "class XORO:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "        self.neuron_1 = Neuron(input_size=2, learning_rate=learning_rate)\n",
    "        self.neuron_2 = Neuron(input_size=2, learning_rate=learning_rate)\n",
    "        self.out_neuron = Neuron(input_size=2, learning_rate=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden_out_1 = self.neuron_1.forward(x)\n",
    "        self.hidden_out_2 = self.neuron_2.forward(x)\n",
    "        self.hidden_outputs = np.array([self.hidden_out_1, self.hidden_out_2])\n",
    "        self.output = self.out_neuron.forward(self.hidden_outputs)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, x, loss):\n",
    "        out_gradient = loss\n",
    "        self.out_neuron.backward(self.hidden_outputs, out_gradient)\n",
    "        hidden_grad_1 = self.out_neuron._weights[0] * out_gradient * self.neuron_1.sigmoid_derivative(self.hidden_outputs[0])\n",
    "        hidden_grad_2 = self.out_neuron._weights[0] * out_gradient * self.neuron_2.sigmoid_derivative(self.hidden_outputs[1])\n",
    "        self.neuron_1.backward(x, hidden_grad_1)\n",
    "        self.neuron_2.backward(x, hidden_grad_2)\n",
    "\n",
    "def XORO_train():\n",
    "    dataset = np.array([\n",
    "        [0,0],\n",
    "        [0,1],\n",
    "        [1,0],\n",
    "        [1,1]\n",
    "    ])\n",
    "    labels = np.array([0,1,1,0])\n",
    "\n",
    "    model = XORO(learning_rate=0.5)\n",
    "    epochs = 10000\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, label in zip(dataset, labels):\n",
    "            output = model.forward(x)\n",
    "            loss = 0.5 * (output - label) ** 2\n",
    "            total_loss += loss\n",
    "\n",
    "            loss_gradient = output - label\n",
    "            model.backward(x, loss_gradient)\n",
    "\n",
    "        if epoch % 1000 == 999:\n",
    "            print(f'Epoch: {epoch+1}, current loss: {total_loss}')\n",
    "\n",
    "    print(\"\\nTesting the XOR Model\")\n",
    "    for x, label in zip(dataset, labels):\n",
    "        output =  model.forward(x)\n",
    "        print(f\"Input: {x}, Predicted: {round(output)}, Actual: {label}\")\n",
    "\n",
    "XORO_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b884c3-191e-47db-9fd8-ea862936c9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36556af2-faea-4597-a90b-2beb358bee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "panel-cell-order": [
   "ae81e8aa-0914-49bf-aba3-62df23deb9e4"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
